{"paragraphs":[{"text":"%python.ipython\n\nimport mxnet as mx\nfor key in (mx.nd.load('/home/rav009/Desktop/Projects/FashionAI2018-TianChi/models/collar_design_labels_resnet50_v2_10_15_final.params').keys()):\n    print(key)","user":"anonymous","dateUpdated":"2021-06-01T14:47:02+0800","progress":0,"config":{"colWidth":12,"fontSize":9,"results":{},"enabled":true,"editorSetting":{}},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Ipython kernel has been stopped. Please check logs. It might be because of an out of memory issue."}]},"apps":[],"runtimeInfos":{},"progressUpdateIntervalMs":500,"jobName":"paragraph_1622460886584_1174298517","id":"paragraph_1622460886584_1174298517","dateCreated":"2021-05-31T19:34:46+0800","dateStarted":"2021-06-01T14:47:03+0800","dateFinished":"2021-06-01T14:47:18+0800","status":"ERROR","focus":false},{"text":"%python.ipython\nimport mxnet as mx\nfrom mxnet import gluon\n\nctx = mx.cpu(0)\nnet = gluon.nn.SymbolBlock.imports(\"/home/rav009/Desktop/Projects/FashionAI2018-TianChi/models/collar_design_labels_resnet50_v2_10_15_final-symbol.json\", ['data'], \"/home/rav009/Desktop/Projects/FashionAI2018-TianChi/models/collar_design_labels_resnet50_v2_10_15_final-0015.params\", ctx=ctx)\nprint(type(net))\n","user":"anonymous","dateUpdated":"2021-06-02T13:56:38+0800","progress":0,"config":{"colWidth":12,"fontSize":9,"results":{},"enabled":true,"editorSetting":{}},"settings":{"params":{},"forms":{}},"apps":[],"runtimeInfos":{},"progressUpdateIntervalMs":500,"jobName":"paragraph_1622613258289_20950619","id":"paragraph_1622613258289_20950619","dateCreated":"2021-06-02T13:54:18+0800","status":"FINISHED","focus":false,"dateFinished":"2021-06-02T13:56:39+0800","dateStarted":"2021-06-02T13:56:38+0800","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"<class 'mxnet.gluon.block.SymbolBlock'>\n"}]}},{"text":"%python.ipython\n\ninput_scale = [448,480,512]\n\ndef ten_crop(img, size):\n    H, W = size\n    iH, iW = img.shape[1:3]\n\n    if iH < H or iW < W:\n        raise ValueError('image size is smaller than crop size')\n\n    img_flip = img[:, :, ::-1]\n\n    crops = nd.stack(\n        img[:, (iH - H) // 2:(iH + H) // 2, (iW - W) // 2:(iW + W) // 2],#center crop\n        img[:, 0:H, 0:W],#left top corner\n        img[:, iH - H:iH, 0:W],#left bottom corner\n        img[:, 0:H, iW - W:iW],#right top corner\n        img[:, iH - H:iH, iW - W:iW],#right bottom corner\n\n        ## new define\n        img[:, 0:H, (iW - W) // 2:(iW + W) // 2], #middle top\n        img[:, iH - H:iH, (iW - W) // 2:(iW + W) // 2],#middle bottom    \n        img[:, (iH - H) // 2:(iH + H) // 2, 0:W],#left middle\n        img[:, (iH - H) // 2:(iH + H) // 2, iW - W:iW],#right middle\n\n        img_flip[:, (iH - H) // 2:(iH + H) // 2, (iW - W) // 2:(iW + W) // 2],\n        img_flip[:, 0:H, 0:W],\n        img_flip[:, iH - H:iH, 0:W],\n        img_flip[:, 0:H, iW - W:iW],\n        img_flip[:, iH - H:iH, iW - W:iW],\n\n        img_flip[:, 0:H, (iW - W) // 2:(iW + W) // 2], #middle top\n        img_flip[:, iH - H:iH, (iW - W) // 2:(iW + W) // 2],#middle bottom    \n        img_flip[:, (iH - H) // 2:(iH + H) // 2, 0:W],#left middle\n        img_flip[:, (iH - H) // 2:(iH + H) // 2, iW - W:iW],#right middle\n\n    )\n    return (crops)","user":"anonymous","dateUpdated":"2021-06-02T14:00:11+0800","progress":0,"config":{"colWidth":12,"fontSize":9,"results":{},"enabled":true,"editorSetting":{}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"runtimeInfos":{},"progressUpdateIntervalMs":500,"jobName":"paragraph_1622454293348_155766626","id":"paragraph_1622454293348_155766626","dateCreated":"2021-05-31T17:44:53+0800","dateStarted":"2021-06-02T14:00:11+0800","dateFinished":"2021-06-02T14:00:11+0800","status":"FINISHED"},{"text":"%python.ipython\n\ndef transform_predict(im, size):\n    im = im.astype('float32') / 255\n    im = image.resize_short(im, size, interp=1)\n    # im = image.resize_short(im, 331)\n    im = nd.transpose(im, (2,0,1))\n    im = mx.nd.image.normalize(im, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n    # im = forty_crop(im, (352, 352))\n    im = ten_crop(im, (448, 448))\n    return (im)","user":"anonymous","dateUpdated":"2021-06-02T14:00:14+0800","progress":0,"config":{"colWidth":12,"fontSize":9,"results":{},"enabled":true,"editorSetting":{}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"runtimeInfos":{},"progressUpdateIntervalMs":500,"jobName":"paragraph_1622455622227_1470517978","id":"paragraph_1622455622227_1470517978","dateCreated":"2021-05-31T18:07:02+0800","dateStarted":"2021-06-02T14:00:14+0800","dateFinished":"2021-06-02T14:00:14+0800","status":"FINISHED"},{"text":"%python.ipython\nfrom mxnet import gluon, image, init, nd\nfrom mxnet import autograd as ag\nimport numpy as np\n\nimg_path = \"/home/rav009/Projects/FashionAI2018-TianChi/train_valid_allset_small/collar_design_labels/train/1/0a1f201a424ba9886964eb05fcbf027a.jpg\"\nimg_path = \"/home/rav009/Projects/FashionAI2018-TianChi/train_valid_allset/collar_design_labels/val/4/0de2a3d180c2471fa8f8d3cdc849feb6.jpg\"\nimg_path = \"/home/rav009/Projects/FashionAI2018-TianChi/train_valid_allset/collar_design_labels/val/3/0c66a21ba753d17670f32848df4ba848.jpg\"\nimg_path = \"/home/rav009/Projects/FashionAI2018-TianChi/train_valid_allset/collar_design_labels/val/2/0be1cc551cd6c641e172f18d7a05fa1a.jpg\"\nimg_path = '/home/rav009/Projects/FashionAI2018-TianChi/train_valid_allset/collar_design_labels/val/0/0b2f11754061fe7f78d43bbe01225648.jpg'\n\nwith open(img_path, 'rb') as f:\n    img = image.imdecode(f.read())\nout_all = np.zeros([5,])\nfor scale in input_scale:\n    data = transform_predict(img, scale)\n    with ag.predict_mode():\n        out = net(data.as_in_context(mx.cpu(0)))  \n        out = nd.SoftmaxActivation(out).mean(axis=0)\n        out_all += out.asnumpy()\nout = out_all / len(input_scale)\nprint(out)","user":"anonymous","dateUpdated":"2021-06-02T14:50:45+0800","progress":0,"config":{"colWidth":12,"fontSize":9,"results":{},"enabled":true,"editorSetting":{}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[0.95096018 0.01692852 0.00448622 0.02650602 0.0011191 ]\n"}]},"apps":[],"runtimeInfos":{},"progressUpdateIntervalMs":500,"jobName":"paragraph_1622455655099_1690004497","id":"paragraph_1622455655099_1690004497","dateCreated":"2021-05-31T18:07:35+0800","dateStarted":"2021-06-02T14:50:45+0800","dateFinished":"2021-06-02T14:53:11+0800","status":"FINISHED","focus":false},{"text":"%python.ipython\n","user":"anonymous","dateUpdated":"2021-05-31T18:49:59+0800","progress":0,"config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{}},"settings":{"params":{},"forms":{}},"apps":[],"runtimeInfos":{},"progressUpdateIntervalMs":500,"jobName":"paragraph_1622458199340_998235021","id":"paragraph_1622458199340_998235021","dateCreated":"2021-05-31T18:49:59+0800","status":"READY"}],"name":"MXNet 预测","id":"2G6UA2YTU","defaultInterpreterGroup":"python","version":"0.9.0","noteParams":{},"noteForms":{},"angularObjects":{},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{},"path":"/My Notebooks/MXNet 预测"}